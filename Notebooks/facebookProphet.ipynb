{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import glob\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import darts\n",
    "from darts import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.models.forecasting.prophet_model import Prophet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    # Convert inputs to numpy arrays for easier calculations\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    # Calculate individual metrics\n",
    "    mae = np.mean(np.abs(predicted - actual))\n",
    "    rmse = np.sqrt(np.mean((predicted - actual) ** 2))\n",
    "    mape = np.mean(np.abs((predicted - actual) / actual)) * 100\n",
    "    mse = np.mean((predicted - actual) ** 2)\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'MSE': mse\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Time Store_Number % family\n",
    "## Records\n",
    "* Store Number : 1 & Family : Automative \n",
    "* Store Number : 2 & Family :Automative\n",
    "* Store Number : 3 & Family :Automative\n",
    "* Store Number : 7 & Family :Automative\n",
    "* Store Number : 1 & Family : Seafood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '2_AUTOMOTIVE'\n",
    "df = pd.read_csv(f'../ProcessedData/GroupData/{fileName}.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['date','sales']]\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data into Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing daily data\n",
    "series = TimeSeries.from_dataframe(df, \"date\", \"sales\", freq='1D', fill_missing_dates=True, fillna_value=0)\n",
    "\n",
    "\n",
    "split_point = 0.80\n",
    "\n",
    "train_series, test_series = series.split_after(split_point)\n",
    "\n",
    "# Set the figure size and style\n",
    "plt.figure(figsize=(18, 6))\n",
    "# Plot the training and testing data\n",
    "train_series.plot(label='Training Data', color='blue', linewidth=1.5, marker='o')\n",
    "test_series.plot(label='Testing Data', color='orange', linewidth=1.5, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Testing Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Global DGV NS Visits')\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FacebookProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet = Prophet(\n",
    "    suppress_stdout_stderror=True,\n",
    "    add_encoders={\n",
    "        'cyclic': {'future': ['month']},\n",
    "        'datetime_attribute': {'future': ['hour', 'dayofweek']},\n",
    "        'position': {'future': ['relative']},\n",
    "        'custom': {'future': [lambda idx: (idx.year - 1950) / 50]},\n",
    "        'transformer': Scaler()\n",
    "    },\n",
    "    add_seasonalities=dict(\n",
    "        name='custom_daily',\n",
    "        seasonal_periods=24,\n",
    "        fourier_order=6,\n",
    "        prior_scale=10.0,\n",
    "        mode='multiplicative'),\n",
    "        country_holidays='US')\n",
    "prophet.fit(train_series)\n",
    "\n",
    "horizan = 30*4\n",
    "\n",
    "# summary = arima_model.model.summary()\n",
    "test_series_ = test_series[0:horizan]\n",
    "plt.figure(figsize=(18, 6))\n",
    "forcast_arima = prophet.predict(horizan)\n",
    "prophet.predict(horizan).plot(marker='o',label='predicted')\n",
    "test_series_.plot(marker='o',label='Actual/Ground truth')\n",
    "# Add title and labels\n",
    "plt.title('Ground truth vs predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Global DGV NS Visits')\n",
    "plt.xticks(forcast_arima.time_index, forcast_arima.time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model_name,model_object,test_series,FileName):\n",
    "    \n",
    "    result_path = f'../ProcessedData/Results/{model_name}/{FileName}'\n",
    "    result_plot_path = f'../ProcessedData/Results/{model_name}/{FileName}/{model_name}_Plots'\n",
    "    os.makedirs(result_path,exist_ok=True)\n",
    "    os.makedirs(result_plot_path,exist_ok=True)\n",
    "\n",
    "        # Set your parameters\n",
    "    window_sizes = [30, 45, 90]\n",
    "    prediction_horizons = [15, 30,35]\n",
    "    slide_steps = [5, 10, 15]\n",
    "\n",
    "    test_series = test_series\n",
    "    model = model_object\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        for prediction_horizon in prediction_horizons:\n",
    "            for slide_step in slide_steps:\n",
    "                print(f'Iteration : Window size : {window_size} Horizan: {prediction_horizon}, Stride : {slide_step}')\n",
    "                evaluation_df = predict_and_evaluate(window_size, prediction_horizon, slide_step, test_series, model,result_plot_path)\n",
    "                evaluation_df.to_csv(f'{result_path}/window_size_{window_size}_horizon_{prediction_horizon}_stride_{slide_step}.csv', index=False)\n",
    "                \n",
    "                print(f'Window_size_{window_size}_prediction_horizon_{prediction_horizon}_slide_step_{slide_step} - Evaluation completed.')\n",
    "        #         break\n",
    "        #     break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebok Prophet Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_plots(input_window,ground_truth,forecast,bypass_information,result_plot_path):\n",
    "\n",
    "    plt.figure(figsize=(30, 6))\n",
    "    input_window.plot(label='Input Data', marker='o')\n",
    "    forecast.plot(label='Predicted', marker='o')\n",
    "    ground_truth.plot(label='Ground Truth', marker='o')\n",
    "    \n",
    "    combined_time_index = input_window.time_index.append(forecast.time_index).append(ground_truth.time_index)\n",
    "    starting_date_of_input_data = input_window.time_index[0].strftime(\"%Y-%m-%d\")\n",
    "    ending_date_of_input_data = input_window.time_index[-1].strftime(\"%Y-%m-%d\")\n",
    "    starting_date_predicted = forecast.time_index[0].strftime(\"%Y-%m-%d\")\n",
    "    ending_date_of_predicted = forecast.time_index[-1].strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    plt.xticks(combined_time_index, combined_time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "    plt.title(f'Results of Input Data from {starting_date_of_input_data} to {ending_date_of_input_data} & Evaluation on from {starting_date_predicted} to {ending_date_of_predicted}', fontsize=16)\n",
    "    plt.ylabel('Quantity Sold', fontsize=14)\n",
    "    plt.xlabel('Dates', fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plot_filename = f\"{result_plot_path}/{bypass_information['window_size']}_{bypass_information['horizon']}_{bypass_information['slide_step']}.png\"\n",
    "    plt.savefig(plot_filename)      \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "# Function to predict and evaluate\n",
    "def get_ground_truth(window_size, prediction_horizon, slide_step, test_series):\n",
    "    ground_truth_list = []\n",
    "    input_window_list = []\n",
    "    num_predictions = len(test_series) - window_size - prediction_horizon + 1\n",
    "    for i in range(0, num_predictions, slide_step):\n",
    "        input_window = test_series[i:i + window_size]\n",
    "        ground_truth = test_series[i + window_size:i + window_size + prediction_horizon]\n",
    "        ground_truth_list.append(ground_truth)\n",
    "        input_window_list.append(input_window)\n",
    "        \n",
    "    return ground_truth_list , input_window_list\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "            \n",
    "\n",
    "model_name = 'prophet'\n",
    "FileName = fileName\n",
    "result_path = f'../ProcessedData/Results/{model_name}/{FileName}'\n",
    "result_plot_path = f'../ProcessedData/Results/{model_name}/{FileName}/{model_name}_Plots'\n",
    "os.makedirs(result_path,exist_ok=True)\n",
    "os.makedirs(result_plot_path,exist_ok=True)\n",
    "\n",
    "window_sizes = [30, 45, 90]\n",
    "prediction_horizons = [15, 30, 35]\n",
    "slide_steps = [5, 10, 15]\n",
    "test_series = test_series\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    for prediction_horizon in prediction_horizons:\n",
    "        for slide_step in slide_steps:\n",
    "            \n",
    "            ground_truths,input_windows = get_ground_truth(window_size,prediction_horizon,slide_step,test_series)\n",
    "            \n",
    "            predictions =prophet.historical_forecasts(series=test_series ,\n",
    "                                            num_samples=1, \n",
    "                                            train_length=window_size, \n",
    "                                            start=None, \n",
    "                                            forecast_horizon=prediction_horizon, \n",
    "                                            stride=slide_step, \n",
    "                                            retrain=True, \n",
    "                                            overlap_end=False,\n",
    "                                            last_points_only=False, \n",
    "                                            verbose=False, \n",
    "                                            show_warnings=True, \n",
    "                                            predict_likelihood_parameters=False, \n",
    "                                            enable_optimization=True)\n",
    "            \n",
    "            meta_information_evaluation = {\n",
    "                    'Iterations': [],\n",
    "                    'MAE': [],\n",
    "                    'RMSE': [],\n",
    "                    'MAPE': [],\n",
    "                    'MSE': [],\n",
    "                    'input_window_size': [],\n",
    "                    'horizon': [],\n",
    "                    'stride': []\n",
    "                }\n",
    "                \n",
    "            stride=0\n",
    "            for i in range(len(predictions)):\n",
    "                input_window = input_windows[i]\n",
    "                ground_truth = ground_truths[i]\n",
    "                forecast = predictions[i]\n",
    "                sample = forecast.pd_dataframe().reset_index()\n",
    "                sample['sales'] = df['sales'].apply(lambda val : 0  if val <0 else val)\n",
    "                sample = sample[['date','sales']]\n",
    "                forecast = TimeSeries.from_dataframe(sample,time_col='date',value_cols  = 'sales',freq='1D')\n",
    "\n",
    "                \n",
    "                bypass_information = {\n",
    "                    'slide_step':stride,\n",
    "                    'window_size':window_size,\n",
    "                    'horizon':prediction_horizon,            \n",
    "                }\n",
    "                make_plots(input_window,ground_truth,forecast,bypass_information,result_plot_path)\n",
    "                \n",
    "                actual = ground_truth.values().flatten().tolist()\n",
    "                predicted = forecast.values().flatten().tolist()\n",
    "                metrics = calculate_metrics(actual, predicted)\n",
    "                \n",
    "                meta_information_evaluation['Iterations'].append(stride)\n",
    "                meta_information_evaluation['MAE'].append(metrics['MAE'])\n",
    "                meta_information_evaluation['RMSE'].append(metrics['RMSE'])\n",
    "                meta_information_evaluation['MAPE'].append(metrics['MAPE'])\n",
    "                meta_information_evaluation['MSE'].append(metrics['MSE'])\n",
    "                meta_information_evaluation['input_window_size'].append(window_size)\n",
    "                meta_information_evaluation['horizon'].append(prediction_horizon)\n",
    "                meta_information_evaluation['stride'].append(slide_step)\n",
    "        \n",
    "                stride += slide_step\n",
    "                \n",
    "            evaluation_df = pd.DataFrame.from_dict(meta_information_evaluation)\n",
    "            evaluation_df.to_csv(f'{result_path}/window_size_{window_size}_horizon_{prediction_horizon}_stride_{slide_step}.csv', index=False)\n",
    "    #         break\n",
    "        \n",
    "    #     break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_size</th>\n",
       "      <th>horizan</th>\n",
       "      <th>stride</th>\n",
       "      <th>AVG_MAE</th>\n",
       "      <th>AVG_MSE</th>\n",
       "      <th>AVG_RMSE</th>\n",
       "      <th>AVG_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>13.858333</td>\n",
       "      <td>3.677508</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3.013333</td>\n",
       "      <td>15.226667</td>\n",
       "      <td>3.875133</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2.857778</td>\n",
       "      <td>13.782222</td>\n",
       "      <td>3.675262</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>18.638889</td>\n",
       "      <td>4.313142</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>4.252281</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>3.141667</td>\n",
       "      <td>17.336111</td>\n",
       "      <td>4.153545</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>3.280952</td>\n",
       "      <td>18.347619</td>\n",
       "      <td>4.280677</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>4.300083</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>3.233766</td>\n",
       "      <td>17.810390</td>\n",
       "      <td>4.216783</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2.744444</td>\n",
       "      <td>13.322222</td>\n",
       "      <td>3.619536</td>\n",
       "      <td>77.139851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>3.685612</td>\n",
       "      <td>77.530724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>13.311111</td>\n",
       "      <td>3.617140</td>\n",
       "      <td>72.183582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>2.986667</td>\n",
       "      <td>16.146667</td>\n",
       "      <td>4.006184</td>\n",
       "      <td>79.575108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.182728</td>\n",
       "      <td>74.950657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>3.092593</td>\n",
       "      <td>17.448148</td>\n",
       "      <td>4.166103</td>\n",
       "      <td>77.090081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>3.128571</td>\n",
       "      <td>17.071429</td>\n",
       "      <td>4.128033</td>\n",
       "      <td>80.478999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>3.228571</td>\n",
       "      <td>18.276190</td>\n",
       "      <td>4.273937</td>\n",
       "      <td>83.812582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>3.196429</td>\n",
       "      <td>17.939286</td>\n",
       "      <td>4.232144</td>\n",
       "      <td>78.321841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>3.215559</td>\n",
       "      <td>66.181217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>3.521363</td>\n",
       "      <td>59.346561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2.311111</td>\n",
       "      <td>9.422222</td>\n",
       "      <td>3.050470</td>\n",
       "      <td>55.391534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_size horizan stride   AVG_MAE    AVG_MSE  AVG_RMSE   AVG_MAPE\n",
       "5           30      15     10  2.875000  13.858333  3.677508        inf\n",
       "15          30      15     15  3.013333  15.226667  3.875133        inf\n",
       "23          30      15      5  2.857778  13.782222  3.675262        inf\n",
       "14          30      30     10  3.250000  18.638889  4.313142        inf\n",
       "26          30      30     15  3.200000  18.100000  4.252281        inf\n",
       "10          30      30      5  3.141667  17.336111  4.153545        inf\n",
       "16          30      35     10  3.280952  18.347619  4.280677        inf\n",
       "2           30      35     15  3.285714  18.500000  4.300083        inf\n",
       "3           30      35      5  3.233766  17.810390  4.216783        inf\n",
       "8           45      15     10  2.744444  13.322222  3.619536  77.139851\n",
       "20          45      15     15  2.833333  13.666667  3.685612  77.530724\n",
       "18          45      15      5  2.766667  13.311111  3.617140  72.183582\n",
       "19          45      30     10  2.986667  16.146667  4.006184  79.575108\n",
       "11          45      30     15  3.100000  17.500000  4.182728  74.950657\n",
       "9           45      30      5  3.092593  17.448148  4.166103  77.090081\n",
       "4           45      35     10  3.128571  17.071429  4.128033  80.478999\n",
       "7           45      35     15  3.228571  18.276190  4.273937  83.812582\n",
       "13          45      35      5  3.196429  17.939286  4.232144  78.321841\n",
       "12          90      15     10  2.566667  10.433333  3.215559  66.181217\n",
       "25          90      15     15  2.800000  12.400000  3.521363  59.346561\n",
       "24          90      15      5  2.311111   9.422222  3.050470  55.391534"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def aggregate_evaluation_results(file_pattern):\n",
    "    eval_dict = {\n",
    "        'window_size': [],\n",
    "        'horizan': [],\n",
    "        'stride': [],\n",
    "        'AVG_MAE': [],\n",
    "        'AVG_MSE': [],\n",
    "        'AVG_RMSE': [],\n",
    "        'AVG_MAPE': [],\n",
    "    }\n",
    "    \n",
    "    paths = glob.glob(file_pattern)\n",
    "    \n",
    "    for path in paths:\n",
    "        window_size = path.split('/')[-1].split('_')[2]\n",
    "        horizan = path.split('/')[-1].split('_')[4]\n",
    "        stride = path.split('/')[-1].split('_')[6].split('.')[0]\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        eval_dict['window_size'].append(window_size)\n",
    "        eval_dict['horizan'].append(horizan)\n",
    "        eval_dict['stride'].append(stride)\n",
    "\n",
    "        eval_dict['AVG_MAE'].append(df['MAE'].mean())\n",
    "        eval_dict['AVG_MSE'].append(df['MSE'].mean())\n",
    "        eval_dict['AVG_RMSE'].append(df['RMSE'].mean())\n",
    "        eval_dict['AVG_MAPE'].append(df['MAPE'].mean())\n",
    "    \n",
    "    eval_df = pd.DataFrame.from_dict(eval_dict)\n",
    "    eval_df = eval_df.dropna()\n",
    "    eval_df.sort_values(['window_size', 'horizan', 'stride'], inplace=True, ascending=True)\n",
    "    \n",
    "    return eval_df\n",
    "\n",
    "# Example usage\n",
    "file_pattern = f\"../ProcessedData/Results/prophet/{fileName}/*.csv\"\n",
    "result_df = aggregate_evaluation_results(file_pattern)\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2_AUTOMOTIVE'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
